My Experience with Fastai

In this blog post, I want to share my experience of learning deep learning with fastai, a library that simplifies training fast and accurate neural nets using modern best practices1. I will also show some of the projects I have done using fastai and what I have learned from them.

The Reason of Choosing Fastai:

I chose to learn fastai because I was impressed by its philosophy and vision. Fastai is a self-funded research, software development, and teaching lab, focused on making deep learning more accessible. It provides high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, such as computer vision, natural language processing, tabular data, and collaborative filtering. It also provides low-level components that can be mixed and matched to build new approaches.

Another reason I chose fastai is because of its courses. Fastai offers free, online courses that cover both the theory and practice of deep learning. They explain the concepts in a clear and intuitive way, and show how to apply them using fastai. [1]

The Way I Learned Fastai:

I started learning fastai by taking the course Image Processing and Computer Vision. The course covers the basics of deep learning, such as neural networks, convolutional neural networks, recurrent neural networks, data augmentation, regularisation, optimisation, and more. It also introduces the main applications of deep learning, such as image classification, image segmentation, text sentiment analysis, recommendation systems, and tabular models.

The course consists of 10 lessons. The notebooks provide the code and exercises for each lesson. The forum discussions allow the students to ask questions, share their work, and learn from each other.

I followed the course by running the notebooks, doing the exercises, and participating in the forum. I also read the book chapters that corresponded to each lesson. I found the course to be very engaging and informative. I learned a lot of practical skills and tips that helped me to build my own models with fastai. [2]

What I Have Learned from Fastai:

Learning fastai has been a rewarding and enjoyable experience for me. 

Here are some of the things I have learned from fastai:

How to use high-level APIs to quickly build models: 

Fastai provides high-level APIs that abstract away many details and boilerplate code for building models. For example, cnn_learner, unet_learner, text_classifier_learner, collab_learner, and tabular_learner are all functions that create models for different domains with sensible defaults and best practices.

How to use low-level APIs to customise models: 

Fastai also provides low-level APIs that allow more flexibility and control over building models. For example, Learner, DataLoaders, Transforms, Callbacks, Metrics, Optimiser, etc are all classes or functions that can be used to customise different aspects of data processing, training loop, model architecture, etc.

How to use transfer learning to leverage pretrained models: 

Fastai makes it easy to use transfer learning to improve model performance by using pretrained models from other domains or tasks. For example, fine_tune is a method that fine-tunes a model from a pretrained model by freezing and unfreezing different layers.

How to use data augmentation to increase data diversity: 

Fastai provides various data augmentation techniques that can apply random transformations to data during training time. For example, aug_transforms is a function that creates a list of common image augmentations such as flipping, rotating, cropping, warping, etc.

How to use regularisation techniques to prevent overfitting: 

Fastai provides various regularisation techniques that can reduce overfitting by adding noise or penalty to the model or its parameters. For example, Dropout, BatchNorm, Weight Decay, etc are all layers or arguments that can be used to regularise the model.

How to use optimisation techniques to speed up training: 

Fastai provides various optimisation techniques that can speed up training by adjusting the learning rate or momentum dynamically. For example, fit_one_cycle is a method that uses cyclical learning rates and momentum, which can lead to faster convergence and better performance. [3]

Conclusion:

In this blog post, I have shared my experience of learning deep learning with fastai, a library that simplifies training fast and accurate neural nets using modern best practices. I hope you enjoyed reading this post and found it useful. Thank you for reading!


[1] fast.ai, “fast.ai—Making neural nets uncool again,” [Online]. Available: https://www.fast.ai/.

[2] Wikipedia, “Fast.ai,” [Online]. Available: https://en.wikipedia.org/wiki/Fast.ai.

[3] fast.ai, “fast.ai releases new deep learning course, four libraries, and 600-page book,” [Online]. Available: https://www.fast.ai/2020/08/21/fastai2-launch/.
